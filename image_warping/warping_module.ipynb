{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'virt_event_flow' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/data/youssef/virtual_environments/virt_event_flow/bin/python3 -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.4963, 0.2759, 0.3758, 0.8875, 0.2199],\n",
      "          [0.3202, 0.7599, 0.5259, 0.4677, 0.5640],\n",
      "          [0.4305, 0.6116, 0.6129, 0.1376, 0.2845],\n",
      "          [0.2175, 0.9100, 0.6040, 0.9190, 0.0367]],\n",
      "\n",
      "         [[0.2446, 0.9548, 0.0243, 0.3759, 0.2940],\n",
      "          [0.0047, 0.5641, 0.9358, 0.9928, 0.3357],\n",
      "          [0.9138, 0.1978, 0.2200, 0.4004, 0.4588],\n",
      "          [0.2163, 0.6384, 0.9682, 0.8029, 0.3227]]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Create sample alpha masks and optic flow tensors\n",
    "batch_size = 1\n",
    "N = 2\n",
    "H = 4\n",
    "W = 5\n",
    "alpha_masks = torch.rand(batch_size, N, H, W)\n",
    "optic_flow = torch.rand(batch_size, N, 2, H, W)\n",
    "\n",
    "# Element-wise multiply alpha masks and optic flow tensors\n",
    "masked_optic_flow = torch.mul(alpha_masks[:, :, None, :, :], optic_flow)\n",
    "\n",
    "# Sum along the second axis (corresponding to the N dimension)\n",
    "result = torch.sum(masked_optic_flow, dim=1)\n",
    "\n",
    "print(alpha_masks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[[0.8856, 0.4060, 0.4829, 0.3440, 0.3840],\n",
      "           [0.6122, 0.4224, 0.0615, 0.0846, 0.7719],\n",
      "           [0.9120, 0.9590, 0.9448, 0.5211, 0.3415],\n",
      "           [0.8339, 0.1781, 0.9457, 0.2579, 0.3393]],\n",
      "\n",
      "          [[0.6769, 0.4266, 0.2729, 0.9596, 0.2128],\n",
      "           [0.7516, 0.5012, 0.1979, 0.6507, 0.6002],\n",
      "           [0.7527, 0.8575, 0.4613, 0.2216, 0.9076],\n",
      "           [0.0687, 0.1193, 0.8417, 0.0682, 0.6081]]],\n",
      "\n",
      "\n",
      "         [[[0.2527, 0.6347, 0.5653, 0.4942, 0.3779],\n",
      "           [0.8879, 0.4592, 0.4274, 0.9872, 0.7496],\n",
      "           [0.8440, 0.7022, 0.0208, 0.7983, 0.2531],\n",
      "           [0.0117, 0.7993, 0.0673, 0.1947, 0.2727]],\n",
      "\n",
      "          [[0.4098, 0.8266, 0.4844, 0.5917, 0.2095],\n",
      "           [0.3216, 0.6751, 0.3358, 0.3081, 0.5339],\n",
      "           [0.0650, 0.1465, 0.1677, 0.9484, 0.8812],\n",
      "           [0.7920, 0.7748, 0.9251, 0.9074, 0.3668]]]]])\n"
     ]
    }
   ],
   "source": [
    "print(optic_flow)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[[0.4396, 0.1120, 0.1815, 0.3053, 0.0845],\n",
      "           [0.1960, 0.3210, 0.0323, 0.0395, 0.4353],\n",
      "           [0.3926, 0.5865, 0.5791, 0.0717, 0.0971],\n",
      "           [0.1813, 0.1620, 0.5712, 0.2370, 0.0125]],\n",
      "\n",
      "          [[0.3360, 0.1177, 0.1025, 0.8516, 0.0468],\n",
      "           [0.2406, 0.3809, 0.1041, 0.3043, 0.3385],\n",
      "           [0.3240, 0.5244, 0.2827, 0.0305, 0.2582],\n",
      "           [0.0149, 0.1086, 0.5084, 0.0627, 0.0223]]],\n",
      "\n",
      "\n",
      "         [[[0.0618, 0.6060, 0.0137, 0.1858, 0.1111],\n",
      "           [0.0042, 0.2591, 0.4000, 0.9801, 0.2517],\n",
      "           [0.7713, 0.1389, 0.0046, 0.3197, 0.1161],\n",
      "           [0.0025, 0.5102, 0.0652, 0.1563, 0.0880]],\n",
      "\n",
      "          [[0.1002, 0.7893, 0.0118, 0.2224, 0.0616],\n",
      "           [0.0015, 0.3808, 0.3142, 0.3058, 0.1793],\n",
      "           [0.0594, 0.0290, 0.0369, 0.3798, 0.4043],\n",
      "           [0.1713, 0.4946, 0.8957, 0.7286, 0.1184]]]]])\n"
     ]
    }
   ],
   "source": [
    "print(masked_optic_flow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.5014, 0.7180, 0.1952, 0.4911, 0.1956],\n",
      "          [0.2002, 0.5800, 0.4323, 1.0197, 0.6870],\n",
      "          [1.1639, 0.7254, 0.5837, 0.3913, 0.2133],\n",
      "          [0.1839, 0.6722, 0.6364, 0.3933, 0.1005]],\n",
      "\n",
      "         [[0.4362, 0.9070, 0.1143, 1.0740, 0.1084],\n",
      "          [0.2422, 0.7617, 0.4183, 0.6101, 0.5177],\n",
      "          [0.3834, 0.5534, 0.3196, 0.4102, 0.6625],\n",
      "          [0.1862, 0.6032, 1.4041, 0.7912, 0.1407]]]])\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[True, True, True, True, True],\n",
      "          [True, True, True, True, True],\n",
      "          [True, True, True, True, True],\n",
      "          [True, True, True, True, True]],\n",
      "\n",
      "         [[True, True, True, True, True],\n",
      "          [True, True, True, True, True],\n",
      "          [True, True, True, True, True],\n",
      "          [True, True, True, True, True]]]])\n"
     ]
    }
   ],
   "source": [
    "result2 = (optic_flow * alpha_masks[:, :, None, :, :]).sum(1)\n",
    "\n",
    "\n",
    "\n",
    "print(result == result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tqdm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/81/wr37lgjs4nxb0wwc0brmqrpw0000gn/T/ipykernel_16142/3373979052.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_optical_flow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflow_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \"\"\"\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tqdm'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "def get_optical_flow(A, flow_list, coords):\n",
    "    \"\"\"\n",
    "    Calculates estimated optical flow for a given motion model A\n",
    "    Input: A: [batch_size x N_classes x 2 x 3]   2x3   (1,x,y)x1\n",
    "           flow_list: [batch_size x N_classes x 2 x H x W ] list of optical flow (x, y) maps\n",
    "    Output: flow: batch_size x N_classes x 2 x H x W ]tensor of estimated optical flow\n",
    "    \"\"\"\n",
    "    \n",
    "    for b in range(A.shape[0]): # B\n",
    "        for n in range(A.shape[1]): # N_classes  \n",
    "            flow_list[b,n, :, :, :] = torch.matmul(A[b,n,:], coords.view(3, -1)).view(2, flow_list.shape[3], flow_list.shape[4])\n",
    "    return flow_list\n",
    "\n",
    "def get_optical_flow_old(A, flow_list):\n",
    "    \"\"\"\n",
    "    Calculates estimated optical flow for a given motion model A\n",
    "    Input: A: [batch_size x N_classes x 2 x 3]   2x3   (1,x,y)x1\n",
    "           flow_list: [batch_size x N_classes x 2 x H x W ] list of optical flow (x, y) maps\n",
    "    Output: flow: batch_size x N_classes x 2 x H x W ]tensor of estimated optical flow\n",
    "    \"\"\"\n",
    "    B, N_classes, _,  H, W = flow_list.shape\n",
    "    \n",
    "    for b in range(A.shape[0]): # B\n",
    "        for n in range(A.shape[1]): # N_classes\n",
    "            for h in range(H): \n",
    "                for w in range(W):\n",
    "                    u_x, u_y = torch.matmul(A[b,n,:],torch.tensor([1,h,w], device = A.device, dtype = A.dtype))\n",
    "                    flow_list[b,n,h,w,0] = u_x\n",
    "                    flow_list[b,n,h,w,1] = u_y     \n",
    "            \n",
    "    return flow_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/youssef/.pyenv/versions/3.7.13/envs/event_flow/lib/python3.7/site-packages/torch/nn/functional.py:3448: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\"Default grid_sample and affine_grid behavior has changed \"\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def get_optical_flow(A, flow_list, coords):\n",
    "    \"\"\"\n",
    "    Calculates estimated optical flow for a given motion model A\n",
    "    Input: A: [batch_size x N_classes x 2 x 3]   2x3   (1,x,y)x1\n",
    "           flow_list: [batch_size x N_classes x 2 x H x W ] list of optical flow (x, y) maps\n",
    "    Output: flow: batch_size x N_classes x 2 x H x W ]tensor of estimated optical flow\n",
    "    \"\"\"\n",
    "    B, N_classes, _, H, W = flow_list.shape\n",
    "    for b in range(A.shape[0]): # B\n",
    "        for n in range(A.shape[1]): # N_classes  \n",
    "            flow_list[b,n, :, :, :] = torch.matmul(A[b,n,:], coords.view(3, -1)).view(2, H, W)\n",
    "    return flow_list\n",
    "\n",
    "def get_optical_flow_old(A, flow_list):\n",
    "    \"\"\"\n",
    "    Calculates estimated optical flow for a given motion model A\n",
    "    Input: A: [batch_size x N_classes x 2 x 3]   2x3   (1,x,y)x1\n",
    "           flow_list: [batch_size x N_classes x 2 x H x W ] list of optical flow (x, y) maps\n",
    "    Output: flow: batch_size x N_classes x 2 x H x W ]tensor of estimated optical flow\n",
    "    \"\"\"\n",
    "    B, N_classes, _, H, W = flow_list.shape\n",
    "    \n",
    "    for b in range(A.shape[0]): # B\n",
    "        for n in range(A.shape[1]): # N_classes\n",
    "            for h in range(H): \n",
    "                for w in range(W):\n",
    "                    u_x, u_y = torch.matmul(A[b,n,:],torch.tensor([1,h,w], device = A.device, dtype = A.dtype))\n",
    "                    flow_list[b,n,0,h,w] = u_x\n",
    "                    flow_list[b,n,1,h,w] = u_y     \n",
    "            \n",
    "    return flow_list\n",
    "\n",
    "\n",
    "B = 1\n",
    "N_classes = 2\n",
    "H = 4\n",
    "W = 5\n",
    "A = torch.rand(1, 2, 2, 3)\n",
    "flow_list = torch.rand(1, 2, 2, 4, 5)\n",
    "\n",
    "coords = torch.zeros(3, 4, 5)\n",
    "coords[0] = 1\n",
    "coords[1] = torch.arange(H).view(H, 1).repeat(1, W)\n",
    "coords[2] = torch.arange(W).view(1, W).repeat(H, 1)\n",
    "flow_1 = get_optical_flow(A, flow_list, coords)\n",
    "flow_2 = get_optical_flow_old(A, flow_list)\n",
    "flow_3 = torch.nn.functional.affine_grid(A.view(-1,2,3),\n",
    "                                              (B*N_classes, 2, H, W)\n",
    "                                              ).view(B, N_classes, 2, H, W\n",
    "                                                )\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected a batch of 3D affine matrices of shape Nx3x4 for size (1, 2, 2, 4, 5). Got torch.Size([1, 2, 2, 3]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/81/wr37lgjs4nxb0wwc0brmqrpw0000gn/T/ipykernel_32868/573587740.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mflow_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maffine_grid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mflow_list_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maffine_grid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mflow_list_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflow_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.13/envs/event_flow/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36maffine_grid\u001b[0;34m(theta, size, align_corners)\u001b[0m\n\u001b[1;32m   3465\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3466\u001b[0m             raise ValueError(\"Expected a batch of 3D affine matrices of shape Nx3x4 \"\n\u001b[0;32m-> 3467\u001b[0;31m                              \"for size {}. Got {}.\".format(size, theta.shape))\n\u001b[0m\u001b[1;32m   3468\u001b[0m         \u001b[0mspatial_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# spatial dimension sizes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3469\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected a batch of 3D affine matrices of shape Nx3x4 for size (1, 2, 2, 4, 5). Got torch.Size([1, 2, 2, 3])."
     ]
    }
   ],
   "source": [
    "are_equal_old = torch.all(torch.eq(flow_1, flow_2))\n",
    "are_equal_affine = torch.all(torch.eq(flow_1, flow_3))\n",
    "\n",
    "for b in range(B):\n",
    "    flow_list[b,:,:,:,:] = torch.nn.functional.affine_grid(A[b,:,:,:].view(-1,2,3),(N_classes, 2, H, W)).view(N_classes, 2, H, W)\n",
    "\n",
    "\n",
    "print(are_equal_old)\n",
    "print(are_equal_affine)\n",
    "print(torch.all(torch.eq(flow_1, flow_list)))\n",
    "print(torch.all(torch.eq(flow_1, flow_list_2)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.1396,  0.6987,  1.1530, -0.1947],\n",
      "         [ 0.0175,  0.2124,  0.2099,  0.7877],\n",
      "         [ 1.5968, -1.2159, -0.6406,  0.5038]],\n",
      "\n",
      "        [[ 0.6905,  0.1414,  0.8906, -1.7498],\n",
      "         [-0.3110, -0.4238, -0.4851, -0.1280],\n",
      "         [-0.1908, -0.6726,  0.2247,  1.2559]]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "H = 3\n",
    "W = 4\n",
    "\n",
    "\n",
    "# Create the input tensors of shape (2, H, W)\n",
    "alpha = torch.randn(2, H, W)\n",
    "\n",
    "# Compare the two channels element-wise\n",
    "channel_max = torch.max(alpha, dim=0, keepdim=True)[0]\n",
    "\n",
    "# Set all other channel to zero\n",
    "output = torch.where(alpha == channel_max, alpha, torch.zeros_like(alpha))\n",
    "\n",
    "print(alpha)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0000,  0.6987,  1.1530, -0.1947],\n",
      "         [ 0.0175,  0.2124,  0.2099,  0.7877],\n",
      "         [ 1.5968,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.6905,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000, -0.6726,  0.2247,  1.2559]]])\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Create a 100 channel HxW matrix with random values\n",
    "H, W = 2, 3\n",
    "channels = 4\n",
    "matrix = torch.arange(0, 24, step=1,dtype=torch.float64).view(channels,H, W)  # b_tensor expanded to channels\n",
    "\n",
    "\n",
    "# Create a 1x100 vector with random values\n",
    "vector = torch.randn(1, channels)   # w_x tensor\n",
    "# print(vector.expand(H, W, channels))\n",
    "\n",
    "# Add the vector to each value in the matrix\n",
    "matrix += vector.expand(H, W, channels).permute(2, 0, 1)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[1, 2, 3],\n",
    "                  [4, 5, 6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1, 2, 3],\n",
      "         [4, 5, 6]],\n",
      "\n",
      "        [[1, 2, 3],\n",
      "         [4, 5, 6]]])\n"
     ]
    }
   ],
   "source": [
    "a = a.expand(2,2,3)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tensor = torch.tensor([7, 8])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[7, 7, 7],\n",
      "         [7, 7, 7]],\n",
      "\n",
      "        [[8, 8, 8],\n",
      "         [8, 8, 8]]])\n"
     ]
    }
   ],
   "source": [
    "x_tensor = x_tensor.expand(2,3,2).permute(2,0,1)\n",
    "print(x_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = 5\n",
    "W = 6\n",
    "\n",
    "coords= torch.empty(3,H,W)\n",
    "    \n",
    "for h in range(H):\n",
    "    for w in range(W):\n",
    "        coords[0,h,w] = 1\n",
    "        coords[1,h,w] = h\n",
    "        coords[2,h,w] = w\n",
    "\n",
    "print(coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = torch.ones((2,3))\n",
    "kernel[0,:] = 2\n",
    "result = torch.matmul(kernel, coords.view(3, -1)).view(2, 5, 6)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_sorted, _ = torch.sort(tensor, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tensor_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_sorted_cat = torch.cat([torch.zeros([2,1,4,5]), -tensor_sorted], dim = 1)\n",
    "#b_tensor = torch.cumsum(b_tensor,dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tensor_sorted_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_tensor = torch.cumsum(tensor_sorted_cat,dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(b_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "from random import randrange \n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean memory from figures created using plt.figure in previous sessions\n",
    "\n",
    "plt.show(block=False); time.sleep(5); plt.close('all')\n",
    "#plt.get_fignums()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Image_Warping():\n",
    "    \n",
    "    def __init__(self,image_path = \"McS9K.png\", N = 1, circle_radius = 25):\n",
    "        self.path = image_path\n",
    "        self.N = N\n",
    "        self.radius = circle_radius\n",
    "        \n",
    "        self.plot = True\n",
    "        self.img, self.image_shape = self.image_loader()\n",
    "        self.A = self.get_motions_models()\n",
    "        self.alpha_maps = self.get_alpha_maps()\n",
    "        self.rgb_layers = self.get_rgb_layers()\n",
    "        self.flow_x,self.flow_y, self.pixel_x, self.pixel_y = self.get_optical_flow(self.A)\n",
    "        self.new_pixel_x, self.new_pixel_y = self.get_new_pixels()\n",
    "        self.warped_rgb_layer = self.get_warped_rgb_layer()\n",
    "        self.warped_rgb_layers = self.get_warped_layers()\n",
    "        warped_image = self.get_warped_image()\n",
    "        \n",
    "        pass\n",
    "\n",
    "    def image_loader(self, plot = True):\n",
    "        '''load image'''\n",
    "        img = Image.open(self.path)\n",
    "        img = np.asarray(img).copy()\n",
    "\n",
    "        image_shape = img.shape\n",
    "        if plot == True:\n",
    "            plt.figure()\n",
    "            plt.imshow(img)\n",
    "            plt.title(\"Original Image\")\n",
    "            plt.show()\n",
    "        \n",
    "        return img, image_shape\n",
    "\n",
    "    def get_motions_models(self, round = True, scale = 1):\n",
    "\n",
    "        '''create N random affine motions'''\n",
    "        A = np.empty((self.N,2,3))*scale\n",
    "\n",
    "        for i in range(self.N):\n",
    "        \n",
    "\n",
    "            model = np.random.rand(2,3)\n",
    "            model = np.round(model) if round == True else model\n",
    "            if self.N == 1:\n",
    "                A = model\n",
    "            elif self.N > 1:\n",
    "                A[i,:,:] = model\n",
    "\n",
    "        return A \n",
    "\n",
    "    def get_alpha_maps(self, plot = True):\n",
    "\n",
    "        '''create N  alpha maps with shape of a circle'''\n",
    "        \n",
    "        R = self.radius\n",
    "        offset = round(R * 2.1)\n",
    "        x_lim = self.image_shape[1]/2\n",
    "        y_lim = self.image_shape[0]/2\n",
    "        \n",
    "        x_lim = round(x_lim)\n",
    "        y_lim = round(y_lim)\n",
    "\n",
    "        \n",
    "        alpha_maps = []\n",
    "        for _ in range(self.N):\n",
    "            mask = np.zeros(self.image_shape)\n",
    "            alpha_map = cv2.circle(mask,(randrange(R,x_lim-R, offset),randrange(R,y_lim-R, offset)),R,(1,1,1),-1)\n",
    "            if self.N == 1:\n",
    "                alpha_maps = alpha_map    \n",
    "            elif self.N > 1:\n",
    "                alpha_maps.append(alpha_map)\n",
    "                \n",
    "            if plot == True:\n",
    "                plt.figure()\n",
    "                plt.imshow(alpha_map)\n",
    "                plt.title(\"Alpha map\")\n",
    "                plt.show()\n",
    "            \n",
    "        return alpha_maps\n",
    "\n",
    "    def get_rgb_layers(self, plot = True):\n",
    "\n",
    "        '''take alpha maps as input, output rgb layers '''\n",
    "\n",
    "        rgb_layers = []\n",
    "        \n",
    "        for i in range(self.N):\n",
    "            rgb_layer = self.img.copy()\n",
    "            \n",
    "            if self.N == 1:\n",
    "                rgb_layer[self.alpha_maps == 0] = 0 \n",
    "                rgb_layers = rgb_layer\n",
    "\n",
    "            elif self.N > 1:\n",
    "                rgb_layer[self.alpha_maps[i] == 0] = 0 \n",
    "                rgb_layers.append(rgb_layer)\n",
    "            \n",
    "            if plot:\n",
    "                plt.figure()\n",
    "                plt.imshow(rgb_layer)\n",
    "                plt.title(\"RGB layer\")\n",
    "                plt.show()\n",
    "\n",
    "        return rgb_layers\n",
    "    \n",
    "    def get_optical_flow(self, A, round = True):\n",
    "\n",
    "        \n",
    "        pixel_x, pixel_y = np.where(self.rgb_layers[:,:,0] != 0)\n",
    "        #print(type(pixel_x),type(pixel_y))\n",
    "        flow_x = np.zeros((self.rgb_layers.shape[0], self.rgb_layers.shape[1])) \n",
    "        flow_y = flow_x\n",
    "\n",
    "        for i,j in zip(pixel_x,pixel_y):\n",
    "            \n",
    "            u_x, u_y = np.matmul(A,np.array([1,i,j]))\n",
    "            \n",
    "            flow_x[i,j] = u_x\n",
    "            flow_y[i,j] = u_y\n",
    "            \n",
    "        flow = np.stack((flow_x,flow_y), axis = 0)   # flow_x = flow[0,:,:]; flow_y = flow[1,:,:]\n",
    "\n",
    "\n",
    "        return flow_x,flow_y, pixel_x, pixel_y\n",
    "\n",
    "    def get_new_pixels( self, round = True):\n",
    "        \n",
    "        new_pixel_x = self.pixel_x + self.flow_x[self.pixel_x,self.pixel_y]\n",
    "        new_pixel_y = self.pixel_y + self.flow_y[self.pixel_x,self.pixel_y]\n",
    "        \n",
    "        new_pixel_x = np.round(new_pixel_x).astype(int) if round == True else new_pixel_x\n",
    "        new_pixel_y = np.round(new_pixel_y).astype(int) if round == True else new_pixel_y\n",
    "            \n",
    "        return new_pixel_x, new_pixel_y \n",
    "    \n",
    "    def get_warped_rgb_layer(self):\n",
    "        \n",
    "        warped_rgb_layer = np.zeros_like(self.rgb_layers)\n",
    "        warped_rgb_layer[self.new_pixel_x,self.new_pixel_y,:] = self.rgb_layers[self.pixel_x,self.pixel_y,:]\n",
    "        return warped_rgb_layer\n",
    "\n",
    "    def get_warped_layers(self, plot = True):\n",
    "        '''take as input the rgb layers, motion models, and alpha maps, output the warped rgb layers'''\n",
    "        warped_rgb_layers = []\n",
    "        \n",
    "        for i in range(self.N):\n",
    "            if self.N ==1:\n",
    "                self.flow_x,self.flow_y, self.pixel_x, self.pixel_y = self.get_optical_flow(self.A)\n",
    "                new_pixel_x, new_pixel_y = self.get_new_pixels()\n",
    "                warped_rgb_layer = self.get_warped_rgb_layer()\n",
    "                warped_rgb_layers = warped_rgb_layer\n",
    "                \n",
    "            elif self.N > 1:\n",
    "                flow_x, flow_y, pixel_x, pixel_y = self.get_optical_flow(self.A[i,:,:],self.rgb_layers[i]) \n",
    "                new_pixel_x, new_pixel_y = self.get_new_pixels(pixel_x, pixel_y, flow_x, flow_y)\n",
    "                warped_rgb_layer = self.get_warped_rgb_layer(self.rgb_layers[i], new_pixel_x, new_pixel_y, pixel_x, pixel_y)\n",
    "                warped_rgb_layers.append(warped_rgb_layer)\n",
    "            \n",
    "            if plot:\n",
    "                plt.figure()\n",
    "                plt.imshow(warped_rgb_layer)\n",
    "                plt.title(\"Warped RGB layer\")\n",
    "                plt.show()\n",
    "\n",
    "        return warped_rgb_layers\n",
    "    \n",
    "    def get_warped_image(self):\n",
    "        '''take as input the warped rgb layers, output the warped image'''\n",
    "        warped_image = self.img.copy()\n",
    "        plt.figure()\n",
    "        for i in range(self.N):\n",
    "            if self.N == 1:\n",
    "                warped_image[self.warped_rgb_layers != 0] = self.warped_rgb_layers[self.warped_rgb_layers != 0]\n",
    "                break\n",
    "            elif self.N > 1:\n",
    "                warped_image[self.warped_rgb_layers[i] != 0] = self.warped_rgb_layers[i][self.warped_rgb_layers[i] != 0]\n",
    "        plt.imshow(warped_image)\n",
    "        return warped_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\" :\n",
    "\n",
    "    obj = Image_Warping()\n",
    "    warped_image = obj.get_warped_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def image_loader(path, plot = True):\n",
    "    '''\n",
    "    load image\n",
    "    '''\n",
    "    img = Image.open(path)\n",
    "    img = np.asarray(img).copy()\n",
    "    image_shape = img.shape\n",
    "    if plot:\n",
    "        plt.figure()\n",
    "        plt.imshow(img)\n",
    "        plt.title(\"Original image\")\n",
    "        plt.show()\n",
    "    return img, image_shape\n",
    "\n",
    "def get_motions_models(N, round = True, scale = 1):\n",
    "\n",
    "    '''create N random affine motions'''\n",
    "    A = np.empty((N,2,3))*scale\n",
    "\n",
    "    for i in range(N):\n",
    "    \n",
    "        model = np.random.rand(2,3)\n",
    "        model = np.round(model) if round == True else model\n",
    "        if N == 1:\n",
    "            A = model\n",
    "        elif N > 1:\n",
    "            A[i,:,:] = model\n",
    "\n",
    "    return A \n",
    "\n",
    "def get_alpha_maps(N,image_shape, plot = True):\n",
    "    ''' create N random alpha maps with shape of a circle'''\n",
    "    \n",
    "    radius = 25\n",
    "    offset = round(radius * 2.1)\n",
    "    x_lim = image_shape[1]/2\n",
    "    y_lim = image_shape[0]/2\n",
    "    \n",
    "    alpha_maps = []\n",
    "    for _ in range(N):\n",
    "        mask = np.zeros(image_shape)\n",
    "        alpha_map = cv2.circle(mask,(randrange(radius,round(x_lim)-radius, offset),randrange(radius,round(y_lim)-radius, offset)),radius,(1,1,1),-1)\n",
    "        if N == 1:\n",
    "            alpha_maps = alpha_map\n",
    "            \n",
    "        elif N > 1:\n",
    "            alpha_maps.append(alpha_map)\n",
    "        \n",
    "        if plot:\n",
    "            plt.figure()\n",
    "            plt.imshow(alpha_map)\n",
    "            plt.title(\"Alpha map\")\n",
    "            plt.show()\n",
    "         \n",
    "    return alpha_maps\n",
    "\n",
    "def get_rgb_layers(N,alpha_maps,img, plot = True):\n",
    "    '''take alpha maps as input, output rgb layers '''\n",
    "    rgb_layers = []\n",
    "    \n",
    "    for i in range(N):\n",
    "        rgb_layer = img.copy()\n",
    "        if N == 1:\n",
    "            rgb_layer[alpha_maps == 0] = 0 \n",
    "            rgb_layers = rgb_layer\n",
    "            \n",
    "            \n",
    "        elif N > 1:\n",
    "            rgb_layer[alpha_maps[i] == 0] = 0 \n",
    "            rgb_layers.append(rgb_layer)\n",
    "            plt.figure()\n",
    "            plt.imshow(rgb_layer)\n",
    "        \n",
    "        if plot:\n",
    "            plt.figure()\n",
    "            plt.imshow(rgb_layer)\n",
    "            plt.title(\"RGB layer\")\n",
    "            plt.show()\n",
    "        \n",
    "    return rgb_layers \n",
    "\n",
    "def get_optical_flow(A,rgb_layer, round = True):\n",
    "\n",
    "    '''take as input the motion model and the rgb layer, output optic flow according to that rgb layer'''\n",
    "    pixel_x, pixel_y = np.where(rgb_layer[:,:,0] != 0)\n",
    "    flow_x = np.zeros((rgb_layer.shape[0], rgb_layer.shape[1])) \n",
    "    flow_y = flow_x\n",
    "    \n",
    "    for i,j in zip(pixel_x,pixel_y):\n",
    "        \n",
    "        u_x, u_y = np.matmul(A,np.array([1,i,j]))\n",
    "        \n",
    "        flow_x[i,j] = u_x\n",
    "        flow_y[i,j] = u_y\n",
    "        \n",
    "    flow = np.stack((flow_x,flow_y), axis = 0)   # flow_x = flow[0,:,:]; flow_y = flow[1,:,:]\n",
    "\n",
    "    \n",
    "    return flow_x,flow_y, pixel_x, pixel_y\n",
    "\n",
    "def get_new_pixels(pixel_x, pixel_y, flow_x, flow_y, round = True):\n",
    "    '''take as input the pixel coordinates and the flow, output the new pixel coordinates'''\n",
    "    new_pixel_x = pixel_x + flow_x[pixel_x,pixel_y]\n",
    "    new_pixel_y = pixel_y + flow_y[pixel_x,pixel_y]\n",
    "    print(new_pixel_x)\n",
    "    new_pixel_x = np.round(new_pixel_x).astype(int) if round == True else new_pixel_x\n",
    "    new_pixel_y = np.round(new_pixel_y).astype(int) if round == True else new_pixel_y\n",
    "        \n",
    "    return new_pixel_x, new_pixel_y   \n",
    "\n",
    "def get_warped_rgb_layer(rgb_layer, new_pixel_x, new_pixel_y, pixel_x, pixel_y):\n",
    "    '''take as input the rgb layer, new pixel coordinates, and old pixel coordinates, output the warped rgb layer'''\n",
    "    warped_rgb_layer = np.zeros_like(rgb_layer)\n",
    "    warped_rgb_layer[new_pixel_x,new_pixel_y,:] = rgb_layer[pixel_x,pixel_y,:]\n",
    "    return warped_rgb_layer\n",
    "\n",
    "def get_warped_layers(N, rgb_layers, A, alpha_layers, plot = True):\n",
    "    '''take as input the rgb layers, motion models, and alpha maps, output the warped rgb layers'''\n",
    "    warped_rgb_layers = []\n",
    "    \n",
    "    for i in range(N):\n",
    "        if N ==1:\n",
    "            flow_x,flow_y, pixel_x, pixel_y = get_optical_flow(A,rgb_layers)\n",
    "            new_pixel_x, new_pixel_y = get_new_pixels(pixel_x, pixel_y, flow_x, flow_y)\n",
    "            warped_rgb_layer = get_warped_rgb_layer(rgb_layers, new_pixel_x, new_pixel_y, pixel_x, pixel_y)\n",
    "            warped_rgb_layers = warped_rgb_layer\n",
    "        elif N > 1:\n",
    "            flow_x, flow_y, pixel_x, pixel_y = get_optical_flow(A[i,:,:],rgb_layers[i]) \n",
    "            new_pixel_x, new_pixel_y = get_new_pixels(pixel_x, pixel_y, flow_x, flow_y)\n",
    "            warped_rgb_layer = get_warped_rgb_layer(rgb_layers[i], new_pixel_x, new_pixel_y, pixel_x, pixel_y)\n",
    "            warped_rgb_layers.append(warped_rgb_layer)\n",
    "            \n",
    "        if plot:\n",
    "            plt.figure()\n",
    "            plt.imshow(warped_rgb_layer)\n",
    "            plt.title(\"Warped rgb layer\")\n",
    "            plt.show()\n",
    "    return warped_rgb_layers\n",
    "\n",
    "def get_warped_image(N, warped_rgb_layers,img, plot = True):\n",
    "    '''take as input the warped rgb layers, output the warped image'''\n",
    "    warped_image = img.copy()\n",
    "    \n",
    "    for i in range(N):\n",
    "        if N == 1:\n",
    "            warped_image[warped_rgb_layers != 0] = warped_rgb_layers[warped_rgb_layers != 0]\n",
    "            break\n",
    "        elif N > 1:\n",
    "            warped_image[warped_rgb_layers[i] != 0] = warped_rgb_layers[i][warped_rgb_layers[i] != 0]\n",
    "    if plot:\n",
    "        plt.figure()\n",
    "        plt.imshow(warped_image)\n",
    "        plt.title(\"Warped image\")\n",
    "        plt.show()   \n",
    "    return warped_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1\n",
    "img, image_shape = image_loader(\"image_folder/McS9K.png\")\n",
    "alpha_layers = get_alpha_maps(N, image_shape)\n",
    "rgb_layers = get_rgb_layers(N,alpha_layers,img.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = get_motions_models(N, round = False, scale = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warped_rgb_layers = get_warped_layers(N, rgb_layers, A, alpha_layers)\n",
    "warped_image = get_warped_image(N, warped_rgb_layers,img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virt_event_flow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3 (default, Aug 24 2022, 16:28:23) \n[GCC 7.5.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1320ea15e514bec1dae8287b183a2a7470819ab49c5e925fac5c8280dad4bb34"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
