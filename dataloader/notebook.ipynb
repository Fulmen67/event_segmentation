{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "['/home/yousef/Documents/ground_truth_processing/test/ground_truth_images/echo_drone_combinations/gt_echo_X_drone.bag_0.002134982.png', '/home/yousef/Documents/ground_truth_processing/test/ground_truth_images/echo_drone_combinations/gt_echo_X_drone.bag_0.027771803.png', '/home/yousef/Documents/ground_truth_processing/test/ground_truth_images/echo_drone_combinations/gt_echo_X_drone.bag_0.05343992.png', '/home/yousef/Documents/ground_truth_processing/test/ground_truth_images/echo_drone_combinations/gt_echo_X_drone.bag_0.079139123.png', '/home/yousef/Documents/ground_truth_processing/test/ground_truth_images/echo_drone_combinations/gt_echo_X_drone.bag_0.104869205.png', '/home/yousef/Documents/ground_truth_processing/test/ground_truth_images/echo_drone_combinations/gt_echo_X_drone.bag_0.130629955.png', '/home/yousef/Documents/ground_truth_processing/test/ground_truth_images/echo_drone_combinations/gt_echo_X_drone.bag_0.15582344.png', '/home/yousef/Documents/ground_truth_processing/test/ground_truth_images/echo_drone_combinations/gt_echo_X_drone.bag_0.181054899.png', '/home/yousef/Documents/ground_truth_processing/test/ground_truth_images/echo_drone_combinations/gt_echo_X_drone.bag_0.206286358.png', '/home/yousef/Documents/ground_truth_processing/test/ground_truth_images/echo_drone_combinations/gt_echo_X_drone.bag_0.231517818.png', '/home/yousef/Documents/ground_truth_processing/test/ground_truth_images/echo_drone_combinations/gt_echo_X_drone.bag_0.256749277.png', '/home/yousef/Documents/ground_truth_processing/test/ground_truth_images/echo_drone_combinations/gt_echo_X_drone.bag_0.281980736.png', '/home/yousef/Documents/ground_truth_processing/test/ground_truth_images/echo_drone_combinations/gt_echo_X_drone.bag_0.307212195.png', '/home/yousef/Documents/ground_truth_processing/test/ground_truth_images/echo_drone_combinations/gt_echo_X_drone.bag_0.332443654.png', '/home/yousef/Documents/ground_truth_processing/test/ground_truth_images/echo_drone_combinations/gt_echo_X_drone.bag_0.357675114.png', '/home/yousef/Documents/ground_truth_processing/test/ground_truth_images/echo_drone_combinations/gt_echo_X_drone.bag_0.382906573.png', '/home/yousef/Documents/ground_truth_processing/test/ground_truth_images/echo_drone_combinations/gt_echo_X_drone.bag_0.408138032.png', '/home/yousef/Documents/ground_truth_processing/test/ground_truth_images/echo_drone_combinations/gt_echo_X_drone.bag_0.433369491.png', '/home/yousef/Documents/ground_truth_processing/test/ground_truth_images/echo_drone_combinations/gt_echo_X_drone.bag_0.45860095.png', '/home/yousef/Documents/ground_truth_processing/test/ground_truth_images/echo_drone_combinations/gt_echo_X_drone.bag_0.48383241.png', '/home/yousef/Documents/ground_truth_processing/test/ground_truth_images/echo_drone_combinations/gt_echo_X_drone.bag_0.509063869.png', '/home/yousef/Documents/ground_truth_processing/test/ground_truth_images/echo_drone_combinations/gt_echo_X_drone.bag_0.534295328.png', '/home/yousef/Documents/ground_truth_processing/test/ground_truth_images/echo_drone_combinations/gt_echo_X_drone.bag_0.559526787.png', '/home/yousef/Documents/ground_truth_processing/test/ground_truth_images/echo_drone_combinations/gt_echo_X_drone.bag_0.584758246.png', '/home/yousef/Documents/ground_truth_processing/test/ground_truth_images/echo_drone_combinations/gt_echo_X_drone.bag_0.609989706.png', '/home/yousef/Documents/ground_truth_processing/test/ground_truth_images/echo_drone_combinations/gt_echo_X_drone.bag_0.635221165.png', '/home/yousef/Documents/ground_truth_processing/test/ground_truth_images/echo_drone_combinations/gt_echo_X_drone.bag_0.660452624.png', '/home/yousef/Documents/ground_truth_processing/test/ground_truth_images/echo_drone_combinations/gt_echo_X_drone.bag_0.685684083.png', '/home/yousef/Documents/ground_truth_processing/test/ground_truth_images/echo_drone_combinations/gt_echo_X_drone.bag_0.710915542.png', '/home/yousef/Documents/ground_truth_processing/test/ground_truth_images/echo_drone_combinations/gt_echo_X_drone.bag_0.736147002.png', '/home/yousef/Documents/ground_truth_processing/test/ground_truth_images/echo_drone_combinations/gt_echo_X_drone.bag_0.761378461.png', '/home/yousef/Documents/ground_truth_processing/test/ground_truth_images/echo_drone_combinations/gt_echo_X_drone.bag_0.78660992.png', '/home/yousef/Documents/ground_truth_processing/test/ground_truth_images/echo_drone_combinations/gt_echo_X_drone.bag_0.811841379.png', '/home/yousef/Documents/ground_truth_processing/test/ground_truth_images/echo_drone_combinations/gt_echo_X_drone.bag_0.837072838.png', '/home/yousef/Documents/ground_truth_processing/test/ground_truth_images/echo_drone_combinations/gt_echo_X_drone.bag_0.862403587.png', '/home/yousef/Documents/ground_truth_processing/test/ground_truth_images/echo_drone_combinations/gt_echo_X_drone.bag_0.888952744.png', '/home/yousef/Documents/ground_truth_processing/test/ground_truth_images/echo_drone_combinations/gt_echo_X_drone.bag_0.915525412.png', '/home/yousef/Documents/ground_truth_processing/test/ground_truth_images/echo_drone_combinations/gt_echo_X_drone.bag_0.942121327.png', '/home/yousef/Documents/ground_truth_processing/test/ground_truth_images/echo_drone_combinations/gt_echo_X_drone.bag_0.968740222.png', '/home/yousef/Documents/ground_truth_processing/test/ground_truth_images/echo_drone_combinations/gt_echo_X_drone.bag_0.99538183.png']\n"
     ]
    }
   ],
   "source": [
    "path = \"/home/yousef/Documents/ground_truth_processing/test/ground_truth_images/\"\n",
    "lista = []\n",
    "\n",
    "for root, dirs, files in os.walk(path):\n",
    "            list_files = [os.path.join(root, file) for file in files if file.endswith('.png')]\n",
    "            sorted_list_files = sorted(list_files, key=lambda x: float(os.path.basename(x).split('_')[-1].split('.png')[0]))\n",
    "            if list_files:\n",
    "                lista.append(sorted_list_files)\n",
    "            \n",
    "print(len(lista))\n",
    "print(lista[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp: 0.000234523, File: /path/to/gt_april_tag_bird_combinations.bag_0.000234523.png\n",
      "Timestamp: 0.001457522, File: /path/to/gt_april_tag_bird_combinations.bag_0.001457522.png\n",
      "Timestamp: 0.05, File: /path/to/gt_april_tag_bird_combinations.bag_0.050000000.png\n",
      "Timestamp: 0.1, File: /path/to/gt_april_tag_bird_combinations.bag_0.100000000.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Example list of file paths\n",
    "file_paths = [\n",
    "    \"/path/to/gt_april_tag_bird_combinations.bag_0.001457522.png\",\n",
    "    \"/path/to/gt_april_tag_bird_combinations.bag_0.000234523.png\",\n",
    "    \"/path/to/gt_april_tag_bird_combinations.bag_0.100000000.png\",\n",
    "    \"/path/to/gt_april_tag_bird_combinations.bag_0.050000000.png\"\n",
    "]\n",
    "\n",
    "# Extract timestamps and store in a dictionary\n",
    "image_dict = {float(os.path.basename(f).split('_')[-1].split('.png')[0]): f for f in file_paths}\n",
    "\n",
    "# Sort dictionary by timestamp\n",
    "sorted_items = sorted(image_dict.items())  # Sorts by keys (timestamps)\n",
    "\n",
    "# Convert back to a structured list of tuples (timestamp, file_path)\n",
    "sorted_images = [(timestamp, path) for timestamp, path in sorted_items]\n",
    "\n",
    "# Print the sorted results\n",
    "for timestamp, path in sorted_images:\n",
    "    print(f\"Timestamp: {timestamp}, File: {path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.000234523, '/path/to/gt_april_tag_bird_combinations.bag_0.000234523.png'), (0.001457522, '/path/to/gt_april_tag_bird_combinations.bag_0.001457522.png'), (0.05, '/path/to/gt_april_tag_bird_combinations.bag_0.050000000.png'), (0.1, '/path/to/gt_april_tag_bird_combinations.bag_0.100000000.png')]\n"
     ]
    }
   ],
   "source": [
    "print(sorted_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Youssef', 'age': 26, 'major': 'Aerospace Engineering'}\n"
     ]
    }
   ],
   "source": [
    "student = { 'name': 'Youssef', 'age': 26, 'major': 'Aerospace Engineering'}\n",
    "\n",
    "print(student)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(len(student))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Youssef\n"
     ]
    }
   ],
   "source": [
    "print(student.get(\"name\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([('name', 'Youssef'), ('age', 26), ('major', 'Aerospace Engineering')])\n"
     ]
    }
   ],
   "source": [
    "print(student.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a png image\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "file_path = \"/home/yousef/shared_for_test/test_results_EMSGC/echo_bird_combinations/seg_IWEs/0.489271167.png\"\n",
    "image = cv2.imread(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n"
     ]
    }
   ],
   "source": [
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Hue values (labels): [  0   3   4   5   6   7  14  16  19  20  21  22  23  27  29  30  34  37\n",
      "  38  40  41  45  49  50  51  52  53  54  55  59  61  63  64  65  66  68\n",
      "  69  73  74  75  76  77  78  79  81  82  83  84  85  86  87  88  89  90\n",
      "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
      " 109 110 111 112 114 115 116 117 118 119 120 121 122 123 124 125 126 127\n",
      " 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145\n",
      " 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163\n",
      " 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181\n",
      " 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199\n",
      " 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217\n",
      " 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235\n",
      " 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253\n",
      " 254 255]\n"
     ]
    }
   ],
   "source": [
    "# check how many colors are in the image\n",
    "\n",
    "hue, saturation, value = cv2.split(image)\n",
    "unique_hues = np.unique(hue)\n",
    "print(\"Unique Hue values (labels):\", unique_hues)\n",
    "# Display the Hue channel (which corresponds to the labels)\n",
    "# The Hue values are typically in the range [0, 179] in OpenCV\n",
    "#cv2.imshow(\"Hue Channel\", hue)\n",
    "#cv2.waitKey(0)\n",
    "#cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qt.qpa.plugin: Could not find the Qt platform plugin \"wayland\" in \"/home/yousef/.pyenv/versions/event_segmentation/lib/python3.7/site-packages/cv2/qt/plugins\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Load the sparse label map from the text file\n",
    "# Assuming each line in the file is in the format: x y label\n",
    "text_file_path = \"/home/yousef/shared_for_test/test_results_EMSGC/echo_bird_combinations/seg_labels/0.489271167.txt\"\n",
    "labels_data = np.loadtxt(text_file_path, dtype=int)\n",
    "\n",
    "# Assuming the image size is known (width, height)\n",
    "image_width = 640  # Replace with actual width of the image\n",
    "image_height = 480  # Replace with actual height of the image\n",
    "\n",
    "# Initialize a blank (black) binary mask of the same size as the image\n",
    "binary_mask = np.zeros((image_height, image_width), dtype=np.uint8)\n",
    "\n",
    "# Loop through the sparse label data and set corresponding pixels\n",
    "for x, y, label in labels_data:\n",
    "    # Change any label above 1 to 1\n",
    "    if label > 1:\n",
    "        label = 1\n",
    "    binary_mask[y, x] = label * 255  # Set the corresponding pixel to white for label 1\n",
    "\n",
    "# Optionally, apply morphological operations (dilation) to group regions together\n",
    "kernel = np.ones((3, 3), np.uint8)  # Kernel for morphological operations\n",
    "dilated_mask = cv2.dilate(binary_mask, kernel, iterations=3)  # Dilate to group pixels\n",
    "\n",
    "# Perform connected components labeling to group labels correctly\n",
    "num_labels, labels = cv2.connectedComponents(dilated_mask)\n",
    "\n",
    "# Create a binary mask from the connected components (only keeping label 1)\n",
    "# Labels are automatically indexed starting from 0, so we convert label 1 back to 255\n",
    "final_mask = np.zeros_like(dilated_mask)\n",
    "final_mask[labels == 1] = 255  # Only keep the largest connected component\n",
    "\n",
    "# Optionally, refine the mask with further morphological operations (optional)\n",
    "refined_mask = cv2.morphologyEx(final_mask, cv2.MORPH_CLOSE, kernel)  # Close small gaps\n",
    "# Save or visualize the binary mask\n",
    "cv2.imshow('Binary Mask', refined_mask)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Save the mask to a PNG file (optional)\n",
    "cv2.imwrite('binary_mask.png', refined_mask)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "event_segmentation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
